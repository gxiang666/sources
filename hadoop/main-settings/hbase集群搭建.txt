1.上传hbase安装包

2.解压

3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）
	注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下
	
	3.1修改hbase-env.sh
	export JAVA_HOME=/usr/java/jdk1.7.0_55
	//告诉hbase使用外部的zk
	export HBASE_MANAGES_ZK=false
	
	vim hbase-site.xml
	<configuration>
		<!-- 指定hbase在HDFS上存储的路径 -->
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://ns1/hbase</value>
        </property>
		<!-- 指定hbase是分布式的 -->
        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
		<!-- 指定zk的地址，多个用“,”分割 -->
        <property>
                <name>hbase.zookeeper.quorum</name>
                <value>hadoop105:2181,hadoop106:2181,hadoop107:2181</value>
        </property>
	</configuration>
	
	vim regionservers
		hadoop105
		hadoop106
		hadoop107
	
	3.2拷贝hbase到其他节点
		scp -r hbase-0.96.2-hadoop2/ hadoop103:/home/gaoxiang/app
		scp -r hbase-0.96.2-hadoop2/ hadoop104:/home/gaoxiang/app
		scp -r hbase-0.96.2-hadoop2/ hadoop105:/home/gaoxiang/app
		scp -r hbase-0.96.2-hadoop2/ hadoop106:/home/gaoxiang/app
		scp -r hbase-0.96.2-hadoop2/ hadoop107:/home/gaoxiang/app
4.将配置好的HBase拷贝到每一个节点并同步时间。

5.启动所有的hbase
	分别启动zk
		./zkServer.sh start
	启动hbase集群
		start-dfs.sh
	启动hbase，在主节点上运行：
		start-hbase.sh
6.通过浏览器访问hbase管理页面
	192.168.1.201:60010
	启动命令行： hbase shell
7.为保证集群的可靠性，要启动多个HMaster
	hbase-daemon.sh start master
	
	

	
	
